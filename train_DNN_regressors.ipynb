{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#KERAS MODEL DEFINITION\n",
    "from keras.layers import Input, Activation, Dropout, Dense, BatchNormalization, Embedding, concatenate, GRU, Flatten, Lambda, Reshape\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping#, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "# GPU usage\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../dat/train.csv')\n",
    "print(train_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features correlations to target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find most important features relative to target\n",
    "print(\"Find most important features relative to target\")\n",
    "corr = train_df.corr()\n",
    "corr.sort_values([\"SalePrice\"], ascending = False, inplace = True)\n",
    "print(corr.SalePrice)\n",
    "corr.SalePrice.plot(kind = \"barh\")\n",
    "#corr.hist()\n",
    "#sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = train_df.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hist\n",
    "plt.figure(figsize=(12,8))\n",
    "#sns.distplot(train_df.price.values, bins=50, kde=False)\n",
    "y_.hist(bins=50)\n",
    "plt.xlabel('price', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the price is skewed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Log transform of the skewed numerical features to lessen impact of outliers\n",
    "# Inspired by Alexandru Papiu's script : https://www.kaggle.com/apapiu/house-prices-advanced-regression-techniques/regularized-linear-models\n",
    "# As a general rule of thumb, a skewness with an absolute value > 0.5 is considered at least moderately skewed\n",
    "print(skew(y_)) # >0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_ = train_df.SalePrice\n",
    "y = y_log = np.log1p(y_)\n",
    "train_df = train_df.drop('SalePrice', axis=1)\n",
    "train_idx = len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hist log(price)\n",
    "import numpy as np\n",
    "plt.figure(figsize=(12,8))\n",
    "# log(price + 1) to avoid 0's\n",
    "#sns.distplot(np.log(train_df.price + 1).values, bins=50, kde=False)\n",
    "# Same as:\n",
    "#sns.distplot(np.log(train_df['price'] + 1).values, bins=50, kde=False)\n",
    "# Same as :\n",
    "#np.log(train_df.price + 1).hist(bins=50)\n",
    "# Same as:\n",
    "y_log.hist(bins=50)\n",
    "plt.xlabel('price', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(skew(y_log)) # <0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../dat/test.csv')\n",
    "print(test_df.shape)\n",
    "len(test_df.columns) == len(train_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Merge/Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, test_df], axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Handle missing vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of colomns with nulls\n",
    "def check_nulls(df):\n",
    "    print(df.isnull().sum())\n",
    "    return len(df.isnull().sum().nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(check_nulls(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Special colomns handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle missing values for features where median/mean or most common value doesn't make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Alley : data description says NA means \"no alley access\"\n",
    "df.loc[:, \"Alley\"] = df.loc[:, \"Alley\"].fillna(\"NA\")\n",
    "# BedroomAbvGr : NA most likely means 0\n",
    "df.loc[:, \"BedroomAbvGr\"] = df.loc[:, \"BedroomAbvGr\"].fillna(0)\n",
    "# BsmtQual etc : data description says NA for basement features is \"no basement\"\n",
    "df.loc[:, \"BsmtQual\"] = df.loc[:, \"BsmtQual\"].fillna(\"No\")\n",
    "df.loc[:, \"BsmtCond\"] = df.loc[:, \"BsmtCond\"].fillna(\"No\")\n",
    "df.loc[:, \"BsmtExposure\"] = df.loc[:, \"BsmtExposure\"].fillna(\"No\")\n",
    "df.loc[:, \"BsmtFinType1\"] = df.loc[:, \"BsmtFinType1\"].fillna(\"No\")\n",
    "df.loc[:, \"BsmtFinType2\"] = df.loc[:, \"BsmtFinType2\"].fillna(\"No\")\n",
    "df.loc[:, \"BsmtFullBath\"] = df.loc[:, \"BsmtFullBath\"].fillna(0)\n",
    "df.loc[:, \"BsmtHalfBath\"] = df.loc[:, \"BsmtHalfBath\"].fillna(0)\n",
    "df.loc[:, \"BsmtUnfSF\"] = df.loc[:, \"BsmtUnfSF\"].fillna(0)\n",
    "# CentralAir : NA most likely means No\n",
    "df.loc[:, \"CentralAir\"] = df.loc[:, \"CentralAir\"].fillna(\"N\")\n",
    "# Condition : NA most likely means Normal\n",
    "df.loc[:, \"Condition1\"] = df.loc[:, \"Condition1\"].fillna(\"Norm\")\n",
    "df.loc[:, \"Condition2\"] = df.loc[:, \"Condition2\"].fillna(\"Norm\")\n",
    "# EnclosedPorch : NA most likely means no enclosed porch\n",
    "df.loc[:, \"EnclosedPorch\"] = df.loc[:, \"EnclosedPorch\"].fillna(0)\n",
    "# External stuff : NA most likely means average\n",
    "df.loc[:, \"ExterCond\"] = df.loc[:, \"ExterCond\"].fillna(\"TA\")\n",
    "df.loc[:, \"ExterQual\"] = df.loc[:, \"ExterQual\"].fillna(\"TA\")\n",
    "# Fence : data description says NA means \"no fence\"\n",
    "df.loc[:, \"Fence\"] = df.loc[:, \"Fence\"].fillna(\"No\")\n",
    "# FireplaceQu : data description says NA means \"no fireplace\"\n",
    "df.loc[:, \"FireplaceQu\"] = df.loc[:, \"FireplaceQu\"].fillna(\"No\")\n",
    "df.loc[:, \"Fireplaces\"] = df.loc[:, \"Fireplaces\"].fillna(0)\n",
    "# Functional : data description says NA means typical\n",
    "df.loc[:, \"Functional\"] = df.loc[:, \"Functional\"].fillna(\"Typ\")\n",
    "# GarageType etc : data description says NA for garage features is \"no garage\"\n",
    "df.loc[:, \"GarageType\"] = df.loc[:, \"GarageType\"].fillna(\"No\")\n",
    "df.loc[:, \"GarageFinish\"] = df.loc[:, \"GarageFinish\"].fillna(\"No\")\n",
    "df.loc[:, \"GarageQual\"] = df.loc[:, \"GarageQual\"].fillna(\"No\")\n",
    "df.loc[:, \"GarageCond\"] = df.loc[:, \"GarageCond\"].fillna(\"No\")\n",
    "df.loc[:, \"GarageArea\"] = df.loc[:, \"GarageArea\"].fillna(0)\n",
    "df.loc[:, \"GarageCars\"] = df.loc[:, \"GarageCars\"].fillna(0)\n",
    "# HalfBath : NA most likely means no half baths above grade\n",
    "df.loc[:, \"HalfBath\"] = df.loc[:, \"HalfBath\"].fillna(0)\n",
    "# HeatingQC : NA most likely means typical\n",
    "df.loc[:, \"HeatingQC\"] = df.loc[:, \"HeatingQC\"].fillna(\"TA\")\n",
    "# KitchenAbvGr : NA most likely means 0\n",
    "df.loc[:, \"KitchenAbvGr\"] = df.loc[:, \"KitchenAbvGr\"].fillna(0)\n",
    "# KitchenQual : NA most likely means typical\n",
    "df.loc[:, \"KitchenQual\"] = df.loc[:, \"KitchenQual\"].fillna(\"TA\")\n",
    "# LotFrontage : NA most likely means no lot frontage\n",
    "df.loc[:, \"LotFrontage\"] = df.loc[:, \"LotFrontage\"].fillna(0)\n",
    "# LotShape : NA most likely means regular\n",
    "df.loc[:, \"LotShape\"] = df.loc[:, \"LotShape\"].fillna(\"Reg\")\n",
    "# MasVnrType : NA most likely means no veneer\n",
    "df.loc[:, \"MasVnrType\"] = df.loc[:, \"MasVnrType\"].fillna(\"None\")\n",
    "df.loc[:, \"MasVnrArea\"] = df.loc[:, \"MasVnrArea\"].fillna(0)\n",
    "# MiscFeature : data description says NA means \"no misc feature\"\n",
    "df.loc[:, \"MiscFeature\"] = df.loc[:, \"MiscFeature\"].fillna(\"No\")\n",
    "df.loc[:, \"MiscVal\"] = df.loc[:, \"MiscVal\"].fillna(0)\n",
    "# OpenPorchSF : NA most likely means no open porch\n",
    "df.loc[:, \"OpenPorchSF\"] = df.loc[:, \"OpenPorchSF\"].fillna(0)\n",
    "# PavedDrive : NA most likely means not paved\n",
    "df.loc[:, \"PavedDrive\"] = df.loc[:, \"PavedDrive\"].fillna(\"N\")\n",
    "# PoolQC : data description says NA means \"no pool\"\n",
    "df.loc[:, \"PoolQC\"] = df.loc[:, \"PoolQC\"].fillna(\"No\")\n",
    "df.loc[:, \"PoolArea\"] = df.loc[:, \"PoolArea\"].fillna(0)\n",
    "# SaleCondition : NA most likely means normal sale\n",
    "df.loc[:, \"SaleCondition\"] = df.loc[:, \"SaleCondition\"].fillna(\"Normal\")\n",
    "# ScreenPorch : NA most likely means no screen porch\n",
    "df.loc[:, \"ScreenPorch\"] = df.loc[:, \"ScreenPorch\"].fillna(0)\n",
    "# TotRmsAbvGrd : NA most likely means 0\n",
    "df.loc[:, \"TotRmsAbvGrd\"] = df.loc[:, \"TotRmsAbvGrd\"].fillna(0)\n",
    "# Utilities : NA most likely means all public utilities\n",
    "df.loc[:, \"Utilities\"] = df.loc[:, \"Utilities\"].fillna(\"AllPub\")\n",
    "# WoodDeckSF : NA most likely means no wood deck\n",
    "df.loc[:, \"WoodDeckSF\"] = df.loc[:, \"WoodDeckSF\"].fillna(0)\n",
    "# LandSlope : Most likely NA means Mod\n",
    "df.loc[:, \"LandSlope\"] = df.loc[:, \"LandSlope\"].fillna(\"Mod\")\n",
    "# Street : Most likely NaN means Pave\n",
    "df.loc[:, \"Street\"] = df.loc[:, \"Street\"].fillna(\"Pave\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode some categorical features as ordered numbers when there is information in the order.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: Ordinals as numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this setting, we will replace all the ordinal values with numerical ones. \n",
    "\n",
    "They will be scaled normally later.\n",
    "\n",
    "Now, for the sprecially handled missing values, (like None or No), these need to be given an ordinal number as well. Otherwise, the None or No will be counted as strings and the whole var is counted as object, and hence will be handled with OHE+embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = df.replace({\"Alley\" : {\"NA\" : 0, \"Grvl\" : 1, \"Pave\" : 2},\n",
    "                       \"BsmtCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"BsmtExposure\" : {\"No\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n",
    "                       \"BsmtFinType1\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtFinType2\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"ExterCond\" : {\"Po\" : 0, \"Fa\" : 1, \"TA\": 2, \"Gd\": 3, \"Ex\" : 4},\n",
    "                       \"ExterQual\" : {\"Po\" : 0, \"Fa\" : 1, \"TA\": 2, \"Gd\": 3, \"Ex\" : 4},\n",
    "                       \"FireplaceQu\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"Functional\" : {\"Sal\" : 0, \"Sev\" : 1, \"Maj2\" : 2, \"Maj1\" : 3, \"Mod\": 4, \n",
    "                                       \"Min2\" : 5, \"Min1\" : 6, \"Typ\" : 7},\n",
    "                       \"GarageCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"GarageQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"HeatingQC\" : {\"Po\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "                       \"KitchenQual\" : {\"Po\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "                       \"LandSlope\" : {\"Sev\" : 0, \"Mod\" : 1, \"Gtl\" : 2},\n",
    "                       \"LotShape\" : {\"IR3\" : 0, \"IR2\" : 1, \"IR1\" : 2, \"Reg\" : 3},\n",
    "                       \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n",
    "                       \"PoolQC\" : {\"No\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "                       \"Street\" : {\"Grvl\" : 0, \"Pave\" : 1},\n",
    "                       \"Utilities\" : {\"ELO\" : 0, \"NoSeWa\" : 1, \"NoSewr\" : 2, \"AllPub\" : 3}}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ordinal_cols = [\"Alley\", \"BedroomAbvGr\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\", \"BsmtFullBath\", \"BsmtHalfBath\", \"BsmtUnfSF\", \"CentralAir\", \"Condition1\", \"Condition2\", \"EnclosedPorch\", \"ExterCond\", \"ExterQual\", \"Fence\", \"FireplaceQu\", \"Fireplaces\", \"Functional\", \"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\", \"GarageArea\", \"GarageCars\", \"HalfBath\", \"HeatingQC\", \"KitchenAbvGr\", \"KitchenQual\", \"LotFrontage\", \"LotShape\", \"MasVnrType\", \"MasVnrArea\", \"MiscFeature\", \"MiscVal\", \"OpenPorchSF\", \"PavedDrive\", \"PoolQC\", \"PoolArea\", \"SaleCondition\", \"ScreenPorch\", \"TotRmsAbvGrd\", \"Utilities\", \"WoodDeckSF\", \"Street\", \"LandSlope\"]\n",
    "ordinal_cols = [\"Alley\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\", \"BsmtQual\", \"ExterCond\", \"ExterQual\", \"FireplaceQu\", \"Functional\", \"GarageCond\", \"GarageQual\", \"HeatingQC\", \"KitchenQual\", \"LandSlope\", \"LotShape\", \"PavedDrive\", \"PoolQC\", \"Street\", \"Utilities\"]\n",
    "print(df[ordinal_cols].dtypes)\n",
    "df[ordinal_cols].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all types are not objects (otherwise they will not be counted as numericals if they are objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ordinal_obj_cols = df[ordinal_cols].select_dtypes(include = [\"object\"]).columns\n",
    "print(len(ordinal_obj_cols))\n",
    "#df[ordinal_obj_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all nominal values have no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(check_nulls(df[ordinal_cols]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check some ordinals before transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in ordinal_cols:\n",
    "    print(df[col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2: ordinal as OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Encode some categorical features as ordered numbers when there is information in the order\n",
    "df[\"Alley\"].astype('object')\n",
    "df[\"BsmtCond\"].astype('object')\n",
    "\n",
    "\n",
    "\"BsmtCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"BsmtExposure\" : {\"No\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n",
    "                       \"BsmtFinType1\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtFinType2\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"ExterCond\" : {\"Po\" : 0, \"Fa\" : 1, \"TA\": 2, \"Gd\": 3, \"Ex\" : 4},\n",
    "                       \"ExterQual\" : {\"Po\" : 0, \"Fa\" : 1, \"TA\": 2, \"Gd\": 3, \"Ex\" : 4},\n",
    "                       \"FireplaceQu\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"Functional\" : {\"Sal\" : 0, \"Sev\" : 1, \"Maj2\" : 2, \"Maj1\" : 3, \"Mod\": 4, \n",
    "                                       \"Min2\" : 5, \"Min1\" : 6, \"Typ\" : 7},\n",
    "                       \"GarageCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"GarageQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"HeatingQC\" : {\"Po\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "                       \"KitchenQual\" : {\"Po\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "                       \"LandSlope\" : {\"Sev\" : 0, \"Mod\" : 1, \"Gtl\" : 2},\n",
    "                       \"LotShape\" : {\"IR3\" : 0, \"IR2\" : 1, \"IR1\" : 2, \"Reg\" : 3},\n",
    "                       \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n",
    "                       \"PoolQC\" : {\"No\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "                       \"Street\" : {\"Grvl\" : 0, \"Pave\" : 1},\n",
    "                       \"Utilities\" : {\"ELO\" : 0, \"NoSeWa\" : 1, \"NoSewr\" : 2, \"AllPub\" : 3}}\n",
    "                     )\n",
    "                     \n",
    "'''                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get categorial colomns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Some numerical features are actually really categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some numerical features are actually really categories\n",
    "df = df.replace({\"MSSubClass\" : {20 : \"SC20\", 30 : \"SC30\", 40 : \"SC40\", 45 : \"SC45\", \n",
    "                                       50 : \"SC50\", 60 : \"SC60\", 70 : \"SC70\", 75 : \"SC75\", \n",
    "                                       80 : \"SC80\", 85 : \"SC85\", 90 : \"SC90\", 120 : \"SC120\", \n",
    "                                       150 : \"SC150\", 160 : \"SC160\", 180 : \"SC180\", 190 : \"SC190\"},\n",
    "                       \"MoSold\" : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\",\n",
    "                                   7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"}\n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_features = df.select_dtypes(include = [\"object\"]).columns\n",
    "print(\"Categorical features : \" + str(len(categorical_features)))\n",
    "df_cat = df[categorical_features]\n",
    "print(df_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(check_nulls(df_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill catgorial Nulls as \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cat = df_cat.fillna(\"None\")\n",
    "print(check_nulls(df_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get numerical colomns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numerical_features = df.select_dtypes(exclude = [\"object\"]).columns\n",
    "numerical_features = numerical_features.drop(\"Id\")\n",
    "print(\"Numerical features : \" + str(len(numerical_features)))\n",
    "df_num = df[numerical_features]\n",
    "#df_num = df_num.drop('Id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_nulls(df_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check some ordinals before transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in ordinal_cols:\n",
    "    print(df_num[col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Fillna of the remaining numerical colomns as median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_num = df_num.fillna(df_num.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check some ordinals before transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in ordinal_cols:\n",
    "    print(df_num[col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Handle skewed numberical cols as log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check some ordinals before transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in ordinal_cols:\n",
    "    print(df_num[col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you will never reach 0 skewed features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Log transform of the skewed numerical features to lessen impact of outliers\n",
    "# Inspired by Alexandru Papiu's script : https://www.kaggle.com/apapiu/house-prices-advanced-regression-techniques/regularized-linear-models\n",
    "# As a general rule of thumb, a skewness with an absolute value > 0.5 is considered at least moderately skewed\n",
    "skew_cols = [col for col in df_num.columns if col not in ordinal_cols]\n",
    "\n",
    "skewness = df_num[skew_cols].apply(lambda x: skew(x))\n",
    "skewness = skewness[abs(skewness) > 0.5]\n",
    "print(str(skewness.shape[0]) + \" skewed numerical features to log transform\")\n",
    "\n",
    "skewed_features = skewness.index\n",
    "print(skewed_features)\n",
    "df_num[skewed_features] = np.log1p(df_num[skewed_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check some ordinals before transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in ordinal_cols:\n",
    "    print(df_num[col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# The next two are wrong because they give 1D array while the scaler expects 2D, a row for each measurement\n",
    "#s = scaler.fit_transform(df_num[\"LotFrontage\"])\n",
    "#s = scaler.fit_transform(df_num[\"LotFrontage\"].values)\n",
    "s = scaler.fit_transform(df_num[[\"LotFrontage\"]])\n",
    "#s = scaler.fit_transform([df_num[\"LotFrontage\"].values])# This one is wrong because it will give ALL the entries as one entry\n",
    "s\n",
    "#df_num[[\"LotFrontage\"]]\n",
    "#[df_num[\"LotFrontage\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "d = df_num\n",
    "for col in df_num.columns:\n",
    "    d[col] = scaler.fit_transform(df_num[[col]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With StandardScaler we get range [-1,1]. This is not exactly what we want, because we don't have negatives. All what we want is to scale in the range [0,1].\n",
    "\n",
    "For that, we have to use MinMaxScaler instead:\n",
    "    \n",
    "    X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "    X_scaled = X_std * (max - min) + min\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "for col in df_num.columns:\n",
    "    df_num[col] = scaler.fit_transform(df_num[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check some ordinals after transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in ordinal_cols:\n",
    "    print(df_num[col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Do NOT encode categorial encoding as OHE for NN\n",
    "We are going to use embedding tables. So the input is an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df_cat.shape)\n",
    "df_cat.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a LabelEncoder\n",
    "Since we want an index, then we need a LabelEncoder per each categorial column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will arrange the embeddings tables info in tuples:\n",
    "    (max_num_categories, emb_sz)\n",
    "    \n",
    "    emb_sz = min(50, (max_num_categories+1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "embeddings = []\n",
    "for col in categorical_features:\n",
    "    df_cat[col] = le.fit_transform(df_cat[col])\n",
    "    # +2 -> +1 for the UNK and +1 for the max itself\n",
    "    embeddings.append((df_cat[col].max() + 2, min(50, int(df_cat[col].max()/2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df_cat.shape)\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(embeddings))\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_emb_concat_sz = 0\n",
    "for emb in embeddings:\n",
    "    total_emb_concat_sz += emb[1]\n",
    "    \n",
    "print(total_emb_concat_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge numerical and categorial colomns again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_num, df_cat], axis = 1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(df.columns))\n",
    "print(df.columns)\n",
    "print(len(numerical_features))\n",
    "print(numerical_features)\n",
    "print(len(categorical_features))\n",
    "print(categorical_features)\n",
    "#categorical_features_OHE = df_cat.columns\n",
    "#print(len(categorical_features_OHE))\n",
    "#print(categorical_features_OHE)\n",
    "numerical_cols_last_idx = len(numerical_features)\n",
    "categorial_cols_start_idx = numerical_cols_last_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have `len(numerical_features)` embeddings table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df[:train_idx]\n",
    "X_test = df[train_idx:]\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X.as_matrix(), y.as_matrix(), test_size=0.25)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#params\n",
    "dr_r = 0.1\n",
    "\n",
    "\n",
    "#Inputs\n",
    "input_l1 = Input(shape=[X.shape[1],])\n",
    "#input_l = K.expand_dims(input_l, axis = -1)\n",
    "#print(input_l._keras_history)\n",
    "input_l = Reshape([X.shape[1],1])(input_l1)\n",
    "print(input_l.shape)\n",
    "\n",
    "\n",
    "# A. Categorial/Embedding stream\n",
    "\n",
    "# Slice the input, for each category, at the poisition = categorial_cols_start_idx + i\n",
    "category = []\n",
    "for i in range(len(embeddings)):\n",
    "    category.append(Lambda(lambda x: x[:,categorial_cols_start_idx + i])(input_l))\n",
    "\n",
    "#Embeddings layers\n",
    "emb_category = []\n",
    "for i in range(len(embeddings)):\n",
    "    emb_category.append(Embedding(embeddings[i][0], embeddings[i][1])(category[i]))\n",
    "\n",
    "# Concat all embeddings\n",
    "cat_l = Flatten()(emb_category[0])\n",
    "for i in range(len(embeddings)-1): \n",
    "    cat_l = concatenate([cat_l, Flatten()(emb_category[i+1])])\n",
    "\n",
    "print(cat_l.shape)\n",
    "\n",
    "# B. Numerical stream\n",
    "\n",
    "# Slice the numerical part of the input\n",
    "numericals = Lambda(lambda x: x[:, :categorial_cols_start_idx])(input_l)\n",
    "# Dense numerical layers\n",
    "num_l = Flatten()(numericals)\n",
    "num_l = Dense(100)(num_l)\n",
    "\n",
    "print(num_l.shape)\n",
    "    \n",
    "# Concat numericals + categorial\n",
    "main_l = concatenate([num_l, cat_l])\n",
    "\n",
    "print(main_l.shape)\n",
    "\n",
    "#main_l = Dropout(dr_r) (Dense(128) (main_l))\n",
    "main_l = Dense(100) (main_l)\n",
    "main_l = Dense(50) (main_l)\n",
    "main_l = Dense(25) (main_l)\n",
    "main_l = Dense(10) (main_l)\n",
    "main_l = Dense(5) (main_l)\n",
    "\n",
    "\n",
    "#output\n",
    "output = Dense(1, activation=\"linear\") (main_l)\n",
    "\n",
    "#model\n",
    "model = Model(input_l1, output)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#lr = 0.007\n",
    "#optimizer = optimizers.Adam(lr)\n",
    "optimizer = optimizers.Adam()\n",
    "#optimizer = optimizers.RMSprop()\n",
    "model.compile(loss=\"mse\", \n",
    "              optimizer=optimizer)\n",
    "\n",
    "epochs = 200\n",
    "BATCH_SIZE = 10\n",
    "steps = int(len(X_train)/BATCH_SIZE) * epochs\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "\n",
    "lr_init, lr_fin = 0.009, 0.006\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "\n",
    "#K.set_value(model.optimizer.lr, lr_init)\n",
    "#K.set_value(model.optimizer.decay, lr_decay)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", verbose=1, save_best_only=True)\n",
    "#X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "#X_train = np.expand_dims(X_train, axis=-1)\n",
    "#X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "#X_val = np.expand_dims(X_val, axis=-1)\n",
    "print(X_train.shape)\n",
    "history = model.fit(X_train, Y_train\n",
    "                    , epochs=epochs\n",
    "                    , batch_size=BATCH_SIZE\n",
    "                    , validation_data = (X_val, Y_val)\n",
    "                    #, validation_split=0.01\n",
    "                    #, callbacks=[TensorBoard('./logs/'+log_subdir)]\n",
    "                    , verbose=1\n",
    "                    , callbacks=[checkpointer]\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "model.load_weights('weights.hdf5')\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "\n",
    "print(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, Y_val)))\n",
    "print(\"Mean Squared Error : \" + str(mean_squared_error(predictions, Y_val)))\n",
    "print(\"Root Mean Squared Error : \" + str(np.sqrt(mean_squared_error(predictions, Y_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model aggregation\n",
    "#X_test = np.expand_dims(X_test, axis=-1)\n",
    "predictions = model.predict(X_test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_prices = np.expm1(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_prices = predicted_prices.reshape([1459,])\n",
    "predicted_prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'Id': test_df.Id, 'SalePrice': predicted_prices})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
